# Artículos y recursos por clasificar

04-2025

***Razonamiento***: 
*  *DeepSeek-R1 Dissection: Understanding PPO & GRPO Without Any Prior Reinforcement Learning Knowledge*  
El artículo explica de forma clara y accesible cómo funciona GRPO (Generalized Reversed PPO), una variante del algoritmo PPO utilizado en aprendizaje por refuerzo. A través de visualizaciones y ejemplos, el autor muestra cómo GRPO permite una exploración más eficiente del entorno sin requerir conocimientos previos en RL. Es una guía pensada para ayudar a comprender los conceptos clave detrás de DeepSeek-R1 y sus mejoras.  [Leer el artículo completo](https://huggingface.co/blog/NormalUhr/grpo)

* **Exploración de la AGI mediante herramientas de código abierto.**  
El repositorio [open-infra-index](https://github.com/deepseek-ai/open-infra-index) de DeepSeek-AI recopila herramientas de infraestructura de inteligencia artificial probadas en producción, destinadas a un desarrollo eficiente de la inteligencia artificial general (AGI) y a fomentar la innovación impulsada por la comunidad.  En febrero de 2025, DeepSeek-AI anunció la apertura de cinco repositorios de código, lanzando uno por día durante su "Semana del Código Abierto 2025". Esta iniciativa busca compartir progresos con total transparencia y contribuir al avance colectivo en el campo de la IA. 
    * Sistema de inferencia DeepSeek-V3/R1
    * DeepEP, una biblioteca de comunicación eficiente para paralelismo experto
    * DeepGEMM, enfocada en operaciones de multiplicación de matrices de alto rendimiento
    * DeepSeek-AI

***Agentes***
* *Introducing the Model Context Protocol*  
Anthropic ha presentado el Model Context Protocol (MCP), un estándar abierto que permite a los desarrolladores conectar asistentes de inteligencia artificial con diversas fuentes de datos, como repositorios de contenido, herramientas empresariales y entornos de desarrollo. MCP facilita la creación de conexiones bidireccionales seguras entre sistemas de IA y fuentes de datos, simplificando las integraciones y mejorando la relevancia de las respuestas generadas por los modelos.  [Leer el artículo completo](https://www.anthropic.com/news/model-context-protocol)

***Cientificos virtuales***:
* *Accelerating Scientific Breakthroughs with an AI Co-Scientist*  
**Resumen en castellano:** Google Research ha desarrollado un sistema de inteligencia artificial llamado AI Co-Scientist, basado en Gemini 2.0, que actúa como colaborador virtual para científicos. Este sistema ayuda a generar nuevas hipótesis y propuestas de investigación, acelerando el ritmo de descubrimientos científicos y biomédicos.  [Leer el artículo completo](https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/)

***Medicina***: 
* [Fudan’s AI Empowered BSI Enables Paralyzed Patients to Walk](https://www.fudan.edu.cn/en/2025/0305/c344a144344/page.htm)  
La tecnología de BSI, desarrollada con asistencia de inteligencia artificial, establece un puente neuronal entre el cerebro y la médula espinal, ofreciendo esperanza a millones de pacientes con lesiones medulares.

***Hitos***:
* *Google's AI 'co-scientist' cracked 10-year superbug problem in just 2 days*  Investigadores del Imperial College London tardaron 10 años en descubrir cómo ciertas superbacterias adquieren resistencia a los antibióticos. Al utilizar una herramienta de inteligencia artificial desarrollada por Google, obtuvieron la misma respuesta en solo dos días.  [Artículo completo](https://www.livescience.com/technology/artificial-intelligence/googles-ai-co-scientist-cracked-10-year-superbug-problem-in-just-2-days)

***Modelos***:
* **EXAONE Deep Released: Setting a New Standard for Reasoning AI*
LG AI Research ha lanzado EXAONE Deep, una inteligencia artificial avanzada que mejora significativamente las capacidades de razonamiento, posicionándose como una competidora destacada en la industria.  [Leer el artículo completo](https://www.lgresearch.ai/blog/view?seq=543)

* *Introducing Mercury, the first commercial-scale diffusion large language model*  
**Resumen en castellano:** Inception Labs ha presentado Mercury, una familia de modelos de lenguaje de gran escala basados en difusión (dLLMs) que ofrecen generación de texto de alta calidad hasta 10 veces más rápida y económica que los modelos actuales.  [Leer el artículo completo](https://www.inceptionlabs.ai/news)

* *Wan2.1-I2V-14B-480P: High-Quality Image-to-Video Generation*Wan-AI ha desarrollado Wan2.1-I2V-14B-480P, un modelo de inteligencia artificial capaz de generar videos de 5 segundos en resolución 480p a partir de imágenes estáticas. Este modelo, que cuenta con 14.000 millones de parámetros, puede producir un video en aproximadamente 4 minutos utilizando una GPU RTX 4090, sin necesidad de técnicas de optimización adicionales. ** [Repositorio en Hugging Face](https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-480P), [2]( https://medium.com/@cognidownunder/wan-2-1-alibabas-open-source-text-to-video-model-changes-everything-ed1dc4c19f85)



* *QwQ-32B: Embracing the Power of Reinforcement Learning*  
Qwen Team ha presentado QwQ-32B, un modelo de lenguaje con 32.000 millones de parámetros que, mediante el uso de aprendizaje por refuerzo, alcanza un rendimiento comparable al de modelos significativamente más grandes como DeepSeek-R1. Este modelo destaca en tareas de razonamiento matemático, programación y resolución general de problemas, integrando capacidades de agente que le permiten utilizar herramientas y adaptarse según el feedback del entorno. [Leer el artículo completo](https://qwenlm.github.io/blog/qwq-32b/)

***HW***
* *NVIDIA DGX Spark: A Grace Blackwell AI Supercomputer on Your Desk*  
NVIDIA ha presentado el DGX Spark, un superordenador de inteligencia artificial de escritorio impulsado por el superchip GB10 Grace Blackwell. Este dispositivo compacto ofrece hasta 1.000 TOPS de rendimiento en IA y cuenta con 128 GB de memoria unificada, permitiendo a desarrolladores y científicos de datos trabajar con modelos de hasta 200.000 millones de parámetros de manera local. Además, viene preinstalado con el conjunto de software de IA de NVIDIA, facilitando la creación, ajuste y despliegue de modelos avanzados. [Artículo completo](https://www.nvidia.com/en-us/products/workstations/dgx-spark/?s=08)







## RAG

- **Paper seminal**: [https://arxiv.org/pdf/2005.11401](https://arxiv.org/pdf/2005.11401)  
- **LightRAG**: [https://lightrag.github.io/](https://lightrag.github.io/), [https://github.com/HKUDS/LightRAG?tab=readme-ov-file](https://github.com/HKUDS/LightRAG?tab=readme-ov-file)  
- **ColPali**: [https://arxiv.org/abs/2407.01449](https://arxiv.org/abs/2407.01449), [https://github.com/illuin-tech/colpali](https://github.com/illuin-tech/colpali)  
- **REALM**: Retrieval-Augmented Language Model Pre-Training (2020): [https://arxiv.org/pdf/2002.08909](https://arxiv.org/pdf/2002.08909)  

* Surveys
  * https://arxiv.org/abs/2312.10997
  * Grafos: https://www.arxiv.org/pdf/2408.08921

## Retrieval-Augmented Generation (RAG)

  - **Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG**  
  - **Autores:** Singh et al. (2024)  
  - **Enlace:** [arXiv:2501.09136v1](https://arxiv.org/pdf/2501.09136v1)  
  - **Resumen:** [Ver resumen completo aquí](https://github.com/detorrespa//AI-Paper-Summaries/tree/main/RAG/Agentic_RAG)

## Agentes

- **Agentes como proxies humanos**:  
  - [https://arxiv.org/abs/2411.10109](https://arxiv.org/abs/2411.10109)  

- **A Generalist Multi-Agent System for Solving Complex Tasks**:  
  - [https://www.microsoft.com/en-us/research/articles/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks/](https://www.microsoft.com/en-us/research/articles/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks/)  

- **TinyTroupe**: LLM-powered multiagent persona simulation for imagination enhancement and business insights  
  - [https://github.com/microsoft/tinytroupe](https://github.com/microsoft/tinytroupe)  

- **Artificial Intelligence, Scientific Discovery, and Product Innovation**:  
  - [https://aidantr.github.io/files/AI_innovation.pdf](https://aidantr.github.io/files/AI_innovation.pdf)  

- **OpenHands**: An Open Platform for AI Software Developers as Generalist Agents  
  - [https://arxiv.org/abs/2407.16741](https://arxiv.org/abs/2407.16741)  

**Investigación automática**

- [https://storm.genie.stanford.edu/](https://storm.genie.stanford.edu/)  
- [https://arxiv.org/abs/2406.06769](https://arxiv.org/abs/2406.06769) (2024)  
- [https://github.com/allenai/discoveryworldh](https://github.com/allenai/discoveryworldh)  
- [https://sakana.ai/ai-scientist/](https://sakana.ai/ai-scientist/)  
- [https://arxiv.org/abs/2408.06292](https://arxiv.org/abs/2408.06292)  
- [https://github.com/SakanaAI/AI-Scientist](https://github.com/SakanaAI/AI-Scientist)  
- [https://arxiv.org/abs/2402.14207](https://arxiv.org/abs/2402.14207)  

---

## Multimodalidad

- **ColPali**:  
  - [https://arxiv.org/abs/2407.01449](https://arxiv.org/abs/2407.01449)  
  - [https://huggingface.co/vidore/colqwen2-v0.1](https://huggingface.co/vidore/colqwen2-v0.1)  
  - [https://github.com/AnswerDotAI/byaldi/tree/main?tab=readme-ov-file](https://github.com/AnswerDotAI/byaldi/tree/main?tab=readme-ov-file)  

- **LLamaOCR**:  
  - [https://github.com/Nutlope/llama-ocr](https://github.com/Nutlope/llama-ocr)  
  - [https://colab.research.google.com/drive/11lGQDbeEhj9hxI9sGfPCv303fAFihHyF?usp=sharing](https://colab.research.google.com/drive/11lGQDbeEhj9hxI9sGfPCv303fAFihHyF?usp=sharing)  

- **LLM2Clip**:  
  - [https://arxiv.org/abs/2411.04997](https://arxiv.org/abs/2411.04997)  
  - [https://huggingface.co/microsoft/LLM2CLIP-Llama-3-8B-Instruct-CC-Finetuned](https://huggingface.co/microsoft/LLM2CLIP-Llama-3-8B-Instruct-CC-Finetuned)  

- **Recognize Anything**: A Strong Image Tagging Model  
  - [https://recognize-anything.github.io/](https://recognize-anything.github.io/)  

- **Meta**:  
  - [https://ai.meta.com/research/movie-gen/](https://ai.meta.com/research/movie-gen/)  
  - **SAM2**: [https://sam2.metademolab.com/](https://sam2.metademolab.com/)  

- **OmniParser for Pure Vision Based GUI Agent**:  
  - [https://microsoft.github.io/OmniParser/](https://microsoft.github.io/OmniParser/)  

- **VisionLLaMA**:  
  - [https://github.com/Meituan-AutoML/VisionLLaMA](https://github.com/Meituan-AutoML/VisionLLaMA)  

- **OpenVoice**:  
  - [Open Voice Site](https://research.myshell.ai/open-voice)  
  - [Open Voice Colab](https://github.com/camenduru/OpenVoice-colab#-colab)  
  - [Open Voice GitHub](https://github.com/myshell-ai/OpenVoice)  
  - [Open Voice Paper](https://arxiv.org/abs/2312.01479)  

- **Trabajos de META en traducción y clonación**:  
  - **SeamlessM4t V2**: Modelo fundacional  
  - **SeamlessExpressive**: Traducción manteniendo expresividad y tono emocional  
  - **SeamlessStreaming**: Speech and text  
  - **Seamless**: Combina las capacidades de los anteriores  
    - [GitHub](https://github.com/facebookresearch/seamless_communication)  
    - [Demo](https://seamless.metademolab.com/expressive/)  

---

## Eliminación de alucinaciones y razonamiento

- **Large Language Models for Mathematical Reasoning: Progresses and Challenges**:  
  - [https://arxiv.org/abs/2402.00157](https://arxiv.org/abs/2402.00157)  

- **Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters**:  
  - [https://arxiv.org/abs/2408.03314](https://arxiv.org/abs/2408.03314)  

- **The Surprising Effectiveness of Test-Time Training for Abstract Reasoning**:  
  - [https://arxiv.org/pdf/2411.07279](https://arxiv.org/pdf/2411.07279)  
  - [https://github.com/Haiyang-W/TokenFormer](https://github.com/Haiyang-W/TokenFormer)  
  - [https://aipapersacademy.com/tokenformer/](https://aipapersacademy.com/tokenformer/)  

- **Tokenformers**:  
  - [https://arxiv.org/abs/2410.23168](https://arxiv.org/abs/2410.23168)  

- **Model Stealing for Any Low-Rank Language Models**:  
  - [https://arxiv.org/abs/2411.07536](https://arxiv.org/abs/2411.07536)  

- **Forge Reasoning (01)**:  
  - [https://nousresearch.com/introducing-the-forge-reasoning-api-beta-and-nous-chat-an-evolution-in-llm-inference/](https://nousresearch.com/introducing-the-forge-reasoning-api-beta-and-nous-chat-an-evolution-in-llm-inference/),  
  - [https://github.com/nousresearch](https://github.com/nousresearch)  

- **STAR**:  
  - [https://arxiv.org/abs/2203.14465](https://arxiv.org/abs/2203.14465)  

- **Let’s Verify Step by Step**:  
  - [https://arxiv.org/abs/2305.20050](https://arxiv.org/abs/2305.20050)  

- **Neurosymbolic**:  
  - [https://github.com/ccclyu/awesome-deeplogic](https://github.com/ccclyu/awesome-deeplogic)  
  - [https://github.com/cpldcpu/MisguidedAttention](https://github.com/cpldcpu/MisguidedAttention)  

---

## Otros
- **RULER**: What’s the Real Context Size of Your Long-Context Language Models?  
  - [https://arxiv.org/abs/2404.06654](https://arxiv.org/abs/2404.06654)  

***Benchmarks***
- **SWE-bench**: Can Language Models Resolve Real-World GitHub Issues?  
  - [https://arxiv.org/abs/2310.06770](https://arxiv.org/abs/2310.06770)  

***Análisis de datos mediante LLMs***
- **Donald Trumps in the Virtual Polls**:  
  - [https://arxiv.org/abs/2411.01582](https://arxiv.org/abs/2411.01582)  

***Impacto de la IA***
- [https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4945566](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4945566)  
- [https://gwern.net/doc/ai/nn/transformer/gpt/codex/2024-harding.pdf](https://gwern.net/doc/ai/nn/transformer/gpt/codex/2024-harding.pdf)  
- [https://uplevelteam.com/blog/ai-for-developer-productivity#:~:text=AI%20tools%20could%2C%20for%20example,not%20by%20eliminating%20the%20person](https://uplevelteam.com/blog/ai-for-developer-productivity#:~:text=AI%20tools%20could%2C%20for%20example,not%20by%20eliminating%20the%20person)  

***Generación de vídeo y diseños 3D***
- **Simplifying, stabilizing, and scaling continuous-time consistency models**:  
  - [https://openai.com/index/simplifying-stabilizing-and-scaling-continuous-time-consistency-models/](https://openai.com/index/simplifying-stabilizing-and-scaling-continuous-time-consistency-models/)  

- **Generative Omnimate**: Separación de vídeo en capas  
  - [https://arxiv.org/abs/2411.16683](https://arxiv.org/abs/2411.16683)  
  - [https://gen-omnimatte.github.io/](https://gen-omnimatte.github.io/)  

- **Edify 3D**: Modelado 3D  
  - [https://arxiv.org/abs/2411.07135](https://arxiv.org/abs/2411.07135)  
  - [https://research.nvidia.com/labs/dir/edify-3d/](https://research.nvidia.com/labs/dir/edify-3d/)  

- **LLaMa-Mesh (3D)**:  
  - [https://arxiv.org/abs/2411.09595](https://arxiv.org/abs/2411.09595)  

---

***Otras arquitecturas***
- **Mamba**  
- **Liquid Foundation Models**: Our First Series of Generative AI Models  
  - [https://www.liquid.ai/liquid-foundation-models#reimagining-model-architectures](https://www.liquid.ai/liquid-foundation-models#reimagining-model-architectures)  
  - **Liquid Time-constant Networks**: [https://arxiv.org/abs/2006.04439](https://arxiv.org/abs/2006.04439)  
  - [https://medium.com/@hession520/liquid-neural-nets-lnns-32ce1bfb045a](https://medium.com/@hession520/liquid-neural-nets-lnns-32ce1bfb045a)  

---

***Jailbreak***
- [https://www.reddit.com/r/ChatGptDAN/comments/1fbxxgm/chat_gpt_jailbreak_demonic_chloe/?force_seo=1](https://www.reddit.com/r/ChatGptDAN/comments/1fbxxgm/chat_gpt_jailbreak_demonic_chloe/?force_seo=1)  
- [https://arxiv.org/abs/2401.06373](https://arxiv.org/abs/2401.06373)  
- [https://arxiv.org/abs/2408.01420](https://arxiv.org/abs/2408.01420)
