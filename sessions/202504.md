# Reading Group (abril)

## 02/04/2025 - Evaluaci√≥n / Agentes I

**Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena** (28 dic 2023 ‚Äì UC Berkeley)  
[OpenReview](https://openreview.net/forum?id=uccHPGDlao) | [GitHub](https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge) | [PPTX Resumen](https://github.com/Mr-McGL/ai-reading-group-bin/raw/refs/heads/main/2025-05-01_Judging_LLM_as_a_Judge.pptx)

<details markdown="1">
<summary><strong>Resumen:</strong></summary>

**Keywords**: Modelos de lenguaje grandes (*LLMs*), preferencia humana, pruebas de evaluaci√≥n, evaluaci√≥n  

La evaluaci√≥n de chatbots es dif√≠cil debido a las amplias capacidades de los chatbots y la inadecuaci√≥n de los benchmarks existentes para medir preferencias humanas. 

* Problema central: necesidad de un m√©todo automatizado, robusto y escalable para evaluar la alineaci√≥n del LLM con las preferencias humanas.
* Propuesta: explorar el uso de LLM como juez para evaluar modelos en preguntas m√°s abiertas, compar√°ndolo con la evaluaci√≥n humana.
* Verificar la concordancia introduciendo dos benchmarks que usan valoraciones humanas como principal m√©trica de evaluaci√≥n. 
* Resultados: los jueces basados en LLMs como GPT-4 pueden igualar las preferencias humanas, alcanzando m√°s del 80% de acuerdo.
* Conclusi√≥n: El LLM como juez es una forma escalable y explicable de aproximar las preferencias humanas, que de otro modo ser√≠an muy costosas de obtener. 

</details>

<!--<details markdown="1">
  <summary><strong>Referencias relevantes:</strong></summary>
</details>-->

<details markdown="1">
  <summary><strong>Otros *papers* (ideas para pr√≥ximos grupos de lectura):</strong></summary>

  * **Intelligence at the Edge of Chaos** (1 mar 2025 - Yale University, Columbia University, Northwestern University, Idaho State University)  
  [arXiv](https://arxiv.org/pdf/2410.02536)  
  **Keywords**: Inteligencia emergente, aut√≥matas celulares elementales, complejidad, edge of chaos, LLMs, representaciones, razonamiento, predicci√≥n de jugadas de ajedrez  
  **Descripci√≥n**: Este estudio explora la relaci√≥n entre la complejidad de sistemas basados en aut√≥matas celulares elementales (ECA) y la emergencia de inteligencia en modelos de lenguaje grandes (*LLMs*). Se entrena una variante modificada del GPT-2 sobre datos generados por diversas reglas de ECA y se eval√∫a su desempe√±o en tareas de razonamiento y predicci√≥n de jugadas de ajedrez. Los resultados indican que la eficiencia de los modelos mejora al preentrenarse con datos de complejidad intermedia, sugiriendo un ‚Äúpunto √≥ptimo‚Äù o "edge of chaos" para el aprendizaje efectivo.

* **Large Language Diffusion Models** (18 feb 2025 ‚Äì Renmin University of China, Ant Group)  
  [arXiv](https://arxiv.org/pdf/2502.09992)  
  **Keywords**: Modelos de lenguaje grandes, difusi√≥n, generative modeling, in-context learning, razonamiento inverso, escalabilidad  
  **Descripci√≥n**: Este estudio introduce LLaDA, un modelo de difusi√≥n para grandes modelos de lenguaje entrenado desde cero bajo un paradigma de preentrenamiento y fine-tuning supervisado. A diferencia de los modelos autoregresivos tradicionales, LLaDA define la distribuci√≥n del modelo mediante un proceso de enmascaramiento aleatorio y un predictor de m√°scaras basado en Transformers, lo que permite capturar dependencias bidireccionales y superar limitaciones inherentes a la generaci√≥n token a token. Los resultados demuestran que LLaDA es competitivo en escalabilidad y rendimiento en tareas de comprensi√≥n, matem√°ticas, generaci√≥n de c√≥digo y di√°logo, estableciendo a los modelos de difusi√≥n como una alternativa prometedora a los enfoques autoregresivos.

* **Frontier Models are Capable of In-context Scheming** (16 ene 2025 ‚Äì Apollo Research)  
  [arXiv](https://arxiv.org/pdf/2412.04984) / [video](https://www.anthropic.com/news/tracing-thoughts-language-model) 
  **Keywords**: modelos frontera, razonamiento in-context, estrategias emergentes, planificaci√≥n, inteligencia artificial  
  **Descripci√≥n**: Este estudio analiza la capacidad de los modelos de inteligencia artificial para generar y ejecutar esquemas complejos basados en el contexto proporcionado, destacando su potencial en tareas de razonamiento estrat√©gico y planificaci√≥n.

* **On the Biology of a Large Language Model** (27 mar 2025 ‚Äì Anthropic)  
  [Transformer Circuits](https://transformer-circuits.pub/2025/attribution-graphs/biology.html)  
  **Keywords**: biolog√≠a de modelos de lenguaje, circuitos de atribuci√≥n, interpretabilidad, an√°lisis de circuitos, Claude 3.5 Haiku  
  **Descripci√≥n**: Este art√≠culo investiga los mecanismos internos utilizados por Claude 3.5 Haiku, el modelo de producci√≥n de Anthropic, a trav√©s de la metodolog√≠a de trazado de circuitos. Se examinan diversos casos de estudio ‚Äìdesde razonamiento multi-paso y planificaci√≥n en poes√≠a hasta diagn√≥sticos m√©dicos y detecci√≥n de entidades‚Äì para revelar c√≥mo el modelo organiza y procesa informaci√≥n internamente, utilizando ‚Äúgrafos de atribuci√≥n‚Äù que act√∫an como un ‚Äúdiagrama de cableado‚Äù de sus procesos computacionales.

* **Circuit Tracing: Revealing Computational Graphs in Language Models** (27 mar 2025 ‚Äì Anthropic)  
  [Transformer Circuits](https://transformer-circuits.pub/2025/attribution-graphs/methods.html)  
  **Keywords**: trazado de circuitos, grafos de atribuci√≥n, interpretabilidad, modelos transformadores, mecanismos de computaci√≥n  
  **Descripci√≥n**: Este art√≠culo describe un m√©todo para revelar los mecanismos subyacentes en el funcionamiento de modelos de lenguaje. Los autores construyen ‚Äúgrafos de atribuci√≥n‚Äù que representan, de forma interpretable, los pasos computacionales que el modelo realiza al procesar una entrada. Se introduce la idea de un ‚Äúmodelo de reemplazo‚Äù, donde se sustituye parte del modelo original por componentes m√°s interpretables, permitiendo analizar interacciones lineales entre caracter√≠sticas y validar circuitos a trav√©s de experimentos de perturbaci√≥n. Adem√°s, se discuten herramientas de visualizaci√≥n y evaluaci√≥n que facilitan la interpretaci√≥n de estos grafos y, por tanto, una comprensi√≥n m√°s profunda de las decisiones del modelo.

</details>  

<!--<details markdown="1">
<summary><strong>Recursos:</strong></summary>
</details>-->



## 02/04/2025 - Multimodalidad

**Image-to-LaTeX Converter for Mathematical Formulas and Text** (7 ago 2024 ‚Äì Saarland University)  
[arXiv](https://arxiv.org/abs/2408.04015)  | [GitHub](https://github.com/d-gurgurov/im2latex?tab=readme-ov-file)  

<details markdown="1">

<summary><strong>Resumen:</strong></summary>


**Keywords**: Multimodalidad, Imagen, Texto, OCR, *transformers*, LoRA  

**Descripci√≥n**: En este proyecto se entrena un modelo encoder-decoder de visi√≥n para generar c√≥digo LaTeX a partir de im√°genes que contienen f√≥rmulas matem√°ticas y texto. Se desarrollan dos versiones: una base, que utiliza un encoder basado en Swin Transformer y un decodificador basado en GPT-2 entrenado con im√°genes generadas autom√°ticamente, y otra afinada mediante Low-Rank Adaptation (LoRA) entrenada con f√≥rmulas manuscritas. Se eval√∫a la calidad de la conversi√≥n mediante la m√©trica BLEU y se comparan los resultados con modelos similares, como Pix2Text, TexTeller y Sumen. El proyecto aporta modelos de c√≥digo abierto y c√≥digo desde cero para la construcci√≥n de estos sistemas con entrenamiento distribuido y optimizaci√≥n en GPU.

</details>

<!--<details markdown="1">
  <summary><strong>Referencias relevantes:</strong></summary>
</details>-->

<details markdown="1">
  <summary><strong>Otros *papers* (ideas para pr√≥ximos grupos de lectura)/recursos:</strong></summary>

  ***Papers:***

  * **MinerU: An Open-Source Solution for Precise Document Content Extraction** (2024 ‚Äì arXiv)  
  [arXiv](https://arxiv.org/abs/2409.18839)  
  **Keywords**: extracci√≥n de contenido, documentos, c√≥digo abierto, visi√≥n por computador  
  **Descripci√≥n**: Este art√≠culo presenta MinerU, una soluci√≥n de c√≥digo abierto para la extracci√≥n precisa de contenido en documentos. Los autores proponen un m√©todo innovador que integra t√©cnicas de procesamiento de imagen y algoritmos de reconocimiento para identificar y extraer informaci√≥n relevante, valid√°ndolo mediante experimentos comparativos.

  * **Reasoning Models Don't Always Say What They Think** (3 abr 2025 ‚Äì Anthropic)  
  [Anthropic](https://www.anthropic.com/research/reasoning-models-dont-say-think)  
  **Keywords**: Modelos de lenguaje, razonamiento, explicaciones no fieles  
  **Descripci√≥n**: Este estudio examina la fidelidad de las explicaciones generadas por modelos de lenguaje en procesos de razonamiento. Se encontr√≥ que, aunque los modelos utilizan pistas proporcionadas en las preguntas para formular sus respuestas, a menudo omiten mencionar estas pistas en sus explicaciones, lo que plantea preocupaciones sobre la transparencia y confiabilidad de sus procesos de razonamiento.

  * **PaperBench: Evaluating AI‚Äôs Abilities to Replicate AI Research** (2025 ‚Äì OpenAI)  
  [OpenAI](https://cdn.openai.com/papers/22265bac-3191-44e5-b057-7aaacd8e90cd/paperbench.pdf)  
  **Keywords**: replicaci√≥n, benchmark, inteligencia artificial, evaluaci√≥n, r√∫bricas  
  **Descripci√≥n**: Este art√≠culo presenta PaperBench, un benchmark dise√±ado para evaluar la capacidad de agentes de IA para replicar investigaciones en el √°mbito de la inteligencia artificial. Los agentes deben replicar por completo los experimentos descritos en 20 art√≠culos presentados en ICML 2024, partiendo de cero y sin utilizar el c√≥digo original. La evaluaci√≥n se fundamenta en r√∫bricas detalladas, co-dise√±adas con los autores de los trabajos, que desglosan cada proceso de replicaci√≥n en m√∫ltiples sub-tareas (desde la implementaci√≥n del c√≥digo hasta la ejecuci√≥n y verificaci√≥n de resultados). Adem√°s, se introduce un evaluador autom√°tico basado en LLM para calificar escalablemente cada intento de replicaci√≥n.  
  **Replica de google**: 
  [AI co-scientist](https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/)  
  [Resultados](https://www.forbes.com/sites/lesliekatz/2025/02/19/google-unveils-ai-co-scientist-to-supercharge-research-breakthroughs/)  
  **Sarkana**:  
  [The AI Scientist Generates its First Peer-Reviewed Scientific Publication](https://sakana.ai/ai-scientist-first-publication/)



  * **Neuroscience-Inspired Artificial Intelligence** (19 jul 2017 ‚Äì Deepmind)  
  [Neuron](https://doi.org/10.1016/j.neuron.2017.06.011)  
  **Keywords**: Inteligencia artificial, neurociencia, modelos inspirados en el cerebro  
  **Descripci√≥n**: Este art√≠culo argumenta que una mejor comprensi√≥n de los cerebros biol√≥gicos puede desempe√±ar un papel vital en la construcci√≥n de m√°quinas inteligentes. Se examinan las interacciones hist√≥ricas entre los campos de la inteligencia artificial y la neurociencia, destacando avances actuales en IA inspirados en el estudio de la computaci√≥n neuronal en humanos y otros animales. Se concluye resaltando temas compartidos que pueden ser clave para avanzar en futuras investigaciones en ambos campos.

  * **LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models** (14 nov 2024 ‚Äì NVIDIA)  
  [arXiv](https://arxiv.org/abs/2411.09595)  
  **Keywords**: Modelos de lenguaje grandes (*LLMs*), generaci√≥n de mallas 3D, integraci√≥n de modalidades, conocimiento espacial, tokenizaci√≥n de mallas  
  **Descripci√≥n**: Este estudio explora la ampliaci√≥n de las capacidades de los *LLMs* entrenados en texto para generar mallas 3D. Se propone representar las coordenadas de los v√©rtices y las definiciones de las caras como texto, lo que permite la integraci√≥n directa sin necesidad de expandir el vocabulario. Se construye un conjunto de datos para *fine-tuning* supervisado que habilita la generaci√≥n de mallas a partir de indicaciones textuales, la producci√≥n de salidas intercaladas (texto y mallas) y la comprensi√≥n de las mallas. Con este enfoque, LLaMA-Mesh alcanza una calidad comparable a la de modelos entrenados desde cero sin afectar el rendimiento en la generaci√≥n textual.

  * **A unified acoustic-to-speech-to-language embedding space captures the neural basis of natural language processing in everyday conversations** (31 mar 2025 ‚Äì Google, Princeton)  
  [Nature Human Behaviour](https://www.nature.com/articles/s41562-025-02105-9)  
  **Keywords**: procesamiento del lenguaje natural, embeddings ac√∫stico-habla-ling√º√≠stica, electrocorticograf√≠a (ECoG), modelo multimodal, conversaciones reales  
  **Descripci√≥n**: Este estudio introduce un marco computacional unificado que integra representaciones ac√∫sticas, de habla y ling√º√≠sticas extra√≠das de un modelo multimodal (*Whisper*) para predecir la actividad neural durante conversaciones cotidianas. Mediante el uso de electrocorticograf√≠a en pacientes durante interacciones naturales, se mapea la alineaci√≥n entre las distintas capas del modelo y las √°reas cerebrales implicadas en la percepci√≥n y producci√≥n del lenguaje, demostrando una correlaci√≥n robusta en la actividad neuronal.

  * **Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems** (31 mar 2025 ‚Äì Google, Meta ...)  
  [arXiv](https://www.arxiv.org/abs/2504.01990) | [github_papers](https://github.com/FoundationAgents/awesome-foundation-agents?tab=readme-ov-file)
  **Keywords**: Modelos de lenguaje grandes (*LLMs*), agentes inteligentes, auto-mejora, evoluci√≥n colaborativa, seguridad  
  **Descripci√≥n**: Este art√≠culo ofrece una revisi√≥n exhaustiva sobre los fundamentos y desaf√≠os en el desarrollo de agentes inteligentes basados en modelos de lenguaje grandes. Se explora una arquitectura modular inspirada en el cerebro humano que integra componentes para la percepci√≥n, memoria, modelado del mundo, procesamiento de recompensas y sistemas an√°logos a las emociones. Adem√°s, se analizan mecanismos de auto-mejora y evoluci√≥n adaptativa, as√≠ como la colaboraci√≥n en sistemas multiagente, subrayando la necesidad de construir sistemas seguros, √©ticos y robustos para su implementaci√≥n en entornos reales.

  ***Recursos:***

  * üî•***LLM Reasoning Papers*** (15 ene 2025 ‚Äì philschmid)  
    Repositorio de art√≠culos  
    [Hugging Face](https://huggingface.co/collections/philschmid/llm-reasoning-papers-66e6abbdf5579b829f214de8)  
    **Descripci√≥n**: Colecci√≥n curada que re√∫ne art√≠culos para mejorar las capacidades de razonamiento de los modelos de lenguaje grandes.  

  * ***Awesome LLM*** (2025 ‚Äì autor: Hannibal046)  
    Repositorio de art√≠culos 
    [GitHub](https://github.com/Hannibal046/Awesome-LLM)  
    **Descripci√≥n**: Repositorio que recopila una amplia variedad de recursos, herramientas y proyectos relacionados con los modelos de lenguaje grandes (LLMs).

  * ***Mixture of Experts Explained*** (11 dic 2023 ‚Äì Hugging Face)  
    Blog  
    [Hugging Face Blog](https://huggingface.co/blog/moe)  
    **Descripci√≥n**: Entrada del blog que explica en detalle el concepto de Mixture of Experts (MoE), sus fundamentos, ventajas, desaf√≠os y aplicaciones en modelos de lenguaje y transformers, con √©nfasis en t√©cnicas de entrenamiento y fine-tuning para modelos dispersos.

  * ***How Scaling Laws Drive Smarter, More Powerful AI*** (12 feb 2025 ‚Äì NVIDIA)  
    Blog  
    [Blog de NVIDIA](https://blogs.nvidia.com/blog/ai-scaling-laws/#:~:text=Scaling%20laws%20describe%20how%20the,parameters%20or%20computational%20resources%20increases.)  
    **Descripci√≥n**: Entrada del blog que detalla c√≥mo las leyes de escalabilidad en IA establecen la relaci√≥n entre la cantidad de datos, par√°metros y recursos computacionales con la mejora en el rendimiento de los modelos. Explica conceptos de preentrenamiento, postentrenamiento y escalado en tiempo de inferencia, poniendo especial √©nfasis en la importancia de aplicar computaci√≥n acelerada para soportar modelos de razonamiento complejo.
  
  * ***Automating GPU Kernel Generation with DeepSeek R1 and Inference Time Scaling*** (fecha ‚Äì NVIDIA Developer)  
    Blog  
    [Developer Blog de NVIDIA](https://developer.nvidia.com/blog/automating-gpu-kernel-generation-with-deepseek-r1-and-inference-time-scaling/)  
    **Descripci√≥n**: Entrada del blog que explica c√≥mo DeepSeek R1 automatiza la generaci√≥n de kernels para GPU, permitiendo optimizar el rendimiento en tiempo de inferencia. El art√≠culo aborda t√©cnicas avanzadas de deep learning para la generaci√≥n eficiente de c√≥digo en GPU y describe c√≥mo el escalado en tiempo de inferencia puede mejorar la eficiencia y capacidad de respuesta de los modelos de inteligencia artificial en producci√≥n.

  * ***NVIDIA: Cursos RAG + Agentes*** (NVIDIA)  
    Curso  
    [Buscar Cursos](https://www.nvidia.com/en-us/training/find-training/) | [RAG 1](https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+S-FX-15+V1) | [RAG 2](https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+S-FX-16+V1)  
    **Descripci√≥n**: Agentes + RAG + Cursos varios
  
  * üî•üî•üî•***Data-optimal scaling laws*** (2025 ‚Äì Life Architect)  
    Blog  
    [Blog](https://lifearchitect.ai/chinchilla/)  
    **Descripci√≥n**: Resumen del escaladado de datos (ratio datos/parametros para maximizar un coste computacional dado)


</details>


<details markdown="1">

<summary><strong>Recursos:</strong></summary>



* üî•***Awesome Multimodal LLMs*** (2024 ‚Äì BradyFU)  
  Repositorio de art√≠culos  
  [GitHub](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models)  
  **Descripci√≥n**: Repositorio que recopila y organiza recursos, herramientas y proyectos relacionados con modelos de lenguaje grandes multimodales, facilitando el acceso a informaci√≥n y ejemplos pr√°cticos sobre esta tem√°tica.


* Vision Parser: üî•üî•üî• Acepta m√∫ltiples modelos. Basado en Ollama.  
  [git](https://github.com/iamarunbrahma/vision-parse)
  
* üî•üî•üî• AnyModel (2025) (image encoder) with Llama 3.2-1B. üî•üî•üî• AnyModal es un framework modular y extensible para integrar diversas modalidades de entrada.
  [git](https://github.com/ritabratamaiti/AnyModal), [HF](https://huggingface.co/AnyModal/LaTeX-OCR-Llama-3.2-1B),  [dataset 1](https://huggingface.co/datasets/unsloth/LaTeX_OCR), [dataset 2](https://huggingface.co/datasets/linxy/LaTeX_OCR)

* MinerU (2025): Converts PDFs into machine-readable formats
  [git](https://github.com/opendatalab/MinerU), [doc](https://mineru.readthedocs.io/en/latest/index.html), [api](https://mineru.readthedocs.io/en/latest/user_guide/usage/api.html)  
  AGPL


* **im2latex** (7 ago 2024 ‚Äì GitHub)  
  [GitHub](https://github.com/d-gurgurov/im2latex?tab=readme-ov-file)  
  **Descripci√≥n**: Repositorio que contiene c√≥digo y documentaci√≥n para un convertidor de im√°genes a LaTeX, facilitando la transformaci√≥n de f√≥rmulas matem√°ticas y texto a c√≥digo LaTeX mediante t√©cnicas de visi√≥n por ordenador.

* **TexTeller** (6 jun 2024 ‚Äì GitHub)  
  [GitHub](https://github.com/OleehyO/TexTeller)  
  **Descripci√≥n**: Repositorio que ofrece un sistema de reconocimiento de f√≥rmulas en im√°genes, permitiendo convertir im√°genes a c√≥digo LaTeX con alta precisi√≥n y robustez, basado en modelos end-to-end y t√©cnicas avanzadas de OCR.

* ‚ö†Ô∏è**Pix2Text** (15 jul 2024 ‚Äì GitHub) ‚≠ê‚≠ê‚≠ê  
  [GitHub](https://github.com/breezedeus/Pix2Text)  
  **Descripci√≥n**: Repositorio que proporciona un modelo para convertir im√°genes en texto. Basado en t√©cnicas de OCR y aprendizaje profundo, destaca por su capacidad de generalizaci√≥n y precisi√≥n en la extracci√≥n de contenido visual.

</details>
