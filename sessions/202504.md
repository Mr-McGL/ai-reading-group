# Reading Group (abril)

## 02/04/2025 - Evaluación / Agentes I

**Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena** (28 dic 2023 – UC Berkeley)  
[OpenReview](https://openreview.net/forum?id=uccHPGDlao) | [GitHub](https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge) | [PPTX Resumen](https://github.com/Mr-McGL/ai-reading-group-bin/raw/refs/heads/main/2025-05-01_Judging_LLM_as_a_Judge.pptx)

<details markdown="1">
<summary><strong>Resumen:</strong></summary>

**Keywords**: Modelos de lenguaje grandes (*LLMs*), preferencia humana, pruebas de evaluación, evaluación  

La evaluación de chatbots es difícil debido a las amplias capacidades de los chatbots y la inadecuación de los benchmarks existentes para medir preferencias humanas. 

* Problema central: necesidad de un método automatizado, robusto y escalable para evaluar la alineación del LLM con las preferencias humanas.
* Propuesta: explorar el uso de LLM como juez para evaluar modelos en preguntas más abiertas, comparándolo con la evaluación humana.
* Verificar la concordancia introduciendo dos benchmarks que usan valoraciones humanas como principal métrica de evaluación. 
* Resultados: los jueces basados en LLMs como GPT-4 pueden igualar las preferencias humanas, alcanzando más del 80% de acuerdo.
* Conclusión: El LLM como juez es una forma escalable y explicable de aproximar las preferencias humanas, que de otro modo serían muy costosas de obtener. 

</details>

<!--<details markdown="1">
  <summary><strong>Referencias relevantes:</strong></summary>
</details>-->

<details markdown="1">
  <summary><strong>Otros *papers* (ideas para próximos grupos de lectura):</strong></summary>

  * **Intelligence at the Edge of Chaos** (1 mar 2025 - Yale University, Columbia University, Northwestern University, Idaho State University)  
  [arXiv](https://arxiv.org/pdf/2410.02536)  
  **Keywords**: Inteligencia emergente, autómatas celulares elementales, complejidad, edge of chaos, LLMs, representaciones, razonamiento, predicción de jugadas de ajedrez  
  **Descripción**: Este estudio explora la relación entre la complejidad de sistemas basados en autómatas celulares elementales (ECA) y la emergencia de inteligencia en modelos de lenguaje grandes (*LLMs*). Se entrena una variante modificada del GPT-2 sobre datos generados por diversas reglas de ECA y se evalúa su desempeño en tareas de razonamiento y predicción de jugadas de ajedrez. Los resultados indican que la eficiencia de los modelos mejora al preentrenarse con datos de complejidad intermedia, sugiriendo un “punto óptimo” o "edge of chaos" para el aprendizaje efectivo.

* **Large Language Diffusion Models** (18 feb 2025 – Renmin University of China, Ant Group)  
  [arXiv](https://arxiv.org/pdf/2502.09992)  
  **Keywords**: Modelos de lenguaje grandes, difusión, generative modeling, in-context learning, razonamiento inverso, escalabilidad  
  **Descripción**: Este estudio introduce LLaDA, un modelo de difusión para grandes modelos de lenguaje entrenado desde cero bajo un paradigma de preentrenamiento y fine-tuning supervisado. A diferencia de los modelos autoregresivos tradicionales, LLaDA define la distribución del modelo mediante un proceso de enmascaramiento aleatorio y un predictor de máscaras basado en Transformers, lo que permite capturar dependencias bidireccionales y superar limitaciones inherentes a la generación token a token. Los resultados demuestran que LLaDA es competitivo en escalabilidad y rendimiento en tareas de comprensión, matemáticas, generación de código y diálogo, estableciendo a los modelos de difusión como una alternativa prometedora a los enfoques autoregresivos.

* **Frontier Models are Capable of In-context Scheming** (16 ene 2025 – Apollo Research)  
  [arXiv](https://arxiv.org/pdf/2412.04984) / [video](https://www.anthropic.com/news/tracing-thoughts-language-model) 
  **Keywords**: modelos frontera, razonamiento in-context, estrategias emergentes, planificación, inteligencia artificial  
  **Descripción**: Este estudio analiza la capacidad de los modelos de inteligencia artificial para generar y ejecutar esquemas complejos basados en el contexto proporcionado, destacando su potencial en tareas de razonamiento estratégico y planificación.

* **On the Biology of a Large Language Model** (27 mar 2025 – Anthropic)  
  [Transformer Circuits](https://transformer-circuits.pub/2025/attribution-graphs/biology.html)  
  **Keywords**: biología de modelos de lenguaje, circuitos de atribución, interpretabilidad, análisis de circuitos, Claude 3.5 Haiku  
  **Descripción**: Este artículo investiga los mecanismos internos utilizados por Claude 3.5 Haiku, el modelo de producción de Anthropic, a través de la metodología de trazado de circuitos. Se examinan diversos casos de estudio –desde razonamiento multi-paso y planificación en poesía hasta diagnósticos médicos y detección de entidades– para revelar cómo el modelo organiza y procesa información internamente, utilizando “grafos de atribución” que actúan como un “diagrama de cableado” de sus procesos computacionales.

* **Circuit Tracing: Revealing Computational Graphs in Language Models** (27 mar 2025 – Anthropic)  
  [Transformer Circuits](https://transformer-circuits.pub/2025/attribution-graphs/methods.html)  
  **Keywords**: trazado de circuitos, grafos de atribución, interpretabilidad, modelos transformadores, mecanismos de computación  
  **Descripción**: Este artículo describe un método para revelar los mecanismos subyacentes en el funcionamiento de modelos de lenguaje. Los autores construyen “grafos de atribución” que representan, de forma interpretable, los pasos computacionales que el modelo realiza al procesar una entrada. Se introduce la idea de un “modelo de reemplazo”, donde se sustituye parte del modelo original por componentes más interpretables, permitiendo analizar interacciones lineales entre características y validar circuitos a través de experimentos de perturbación. Además, se discuten herramientas de visualización y evaluación que facilitan la interpretación de estos grafos y, por tanto, una comprensión más profunda de las decisiones del modelo.

</details>  

<!--<details markdown="1">
<summary><strong>Recursos:</strong></summary>
</details>-->



## 02/04/2025 - Multimodalidad

**Image-to-LaTeX Converter for Mathematical Formulas and Text** (7 ago 2024 – Saarland University)  
[arXiv](https://arxiv.org/abs/2408.04015)  | [GitHub](https://github.com/d-gurgurov/im2latex?tab=readme-ov-file)  

<details markdown="1">

<summary><strong>Resumen:</strong></summary>


**Keywords**: Multimodalidad, Imagen, Texto, OCR, *transformers*, LoRA  

**Descripción**: En este proyecto se entrena un modelo encoder-decoder de visión para generar código LaTeX a partir de imágenes que contienen fórmulas matemáticas y texto. Se desarrollan dos versiones: una base, que utiliza un encoder basado en Swin Transformer y un decodificador basado en GPT-2 entrenado con imágenes generadas automáticamente, y otra afinada mediante Low-Rank Adaptation (LoRA) entrenada con fórmulas manuscritas. Se evalúa la calidad de la conversión mediante la métrica BLEU y se comparan los resultados con modelos similares, como Pix2Text, TexTeller y Sumen. El proyecto aporta modelos de código abierto y código desde cero para la construcción de estos sistemas con entrenamiento distribuido y optimización en GPU.

</details>

<!--<details markdown="1">
  <summary><strong>Referencias relevantes:</strong></summary>
</details>

<details markdown="1">
  <summary><strong>Otros *papers* (ideas para próximos grupos de lectura):</strong></summary>
</details>-->


<details markdown="1">

<summary><strong>Recursos:</strong></summary>

* **im2latex** (7 ago 2024 – GitHub)  
  [GitHub](https://github.com/d-gurgurov/im2latex?tab=readme-ov-file)  
  **Descripción**: Repositorio que contiene código y documentación para un convertidor de imágenes a LaTeX, facilitando la transformación de fórmulas matemáticas y texto a código LaTeX mediante técnicas de visión por ordenador.

* **TexTeller** (6 jun 2024 – GitHub)  
  [GitHub](https://github.com/OleehyO/TexTeller)  
  **Descripción**: Repositorio que ofrece un sistema de reconocimiento de fórmulas en imágenes, permitiendo convertir imágenes a código LaTeX con alta precisión y robustez, basado en modelos end-to-end y técnicas avanzadas de OCR.

* ⚠️**Pix2Text** (15 jul 2024 – GitHub) ⭐⭐⭐  
  [GitHub](https://github.com/breezedeus/Pix2Text)  
  **Descripción**: Repositorio que proporciona un modelo para convertir imágenes en texto. Basado en técnicas de OCR y aprendizaje profundo, destaca por su capacidad de generalización y precisión en la extracción de contenido visual.

</details>
