# Reading Group (abril)

## 02/04/2025 - Evaluación / Agentes I

**Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena** (28 dic 2023 – UC Berkeley)  
[OpenReview](https://openreview.net/forum?id=uccHPGDlao) | [GitHub](https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge) | [PPTX Resumen](https://github.com/Mr-McGL/ai-reading-group-bin/raw/refs/heads/main/2025-05-01_Judging_LLM_as_a_Judge.pptx)

<details markdown="1">
<summary><strong>Resumen:</strong></summary>

**Keywords**: Modelos de lenguaje grandes (*LLMs*), preferencia humana, pruebas de evaluación, evaluación  

La evaluación de chatbots es difícil debido a las amplias capacidades de los chatbots y la inadecuación de los benchmarks existentes para medir preferencias humanas. 

* Problema central: necesidad de un método automatizado, robusto y escalable para evaluar la alineación del LLM con las preferencias humanas.
* Propuesta: explorar el uso de LLM como juez para evaluar modelos en preguntas más abiertas, comparándolo con la evaluación humana.
* Verificar la concordancia introduciendo dos benchmarks que usan valoraciones humanas como principal métrica de evaluación. 
* Resultados: los jueces basados en LLMs como GPT-4 pueden igualar las preferencias humanas, alcanzando más del 80% de acuerdo.
* Conclusión: El LLM como juez es una forma escalable y explicable de aproximar las preferencias humanas, que de otro modo serían muy costosas de obtener. 

</details>

<!--<details markdown="1">
  <summary><strong>Referencias relevantes:</strong></summary>
</details>-->

<details markdown="1">
  <summary><strong>Otros *papers* (ideas para próximos grupos de lectura):</strong></summary>

  * **Intelligence at the Edge of Chaos** (1 mar 2025 - Yale University, Columbia University, Northwestern University, Idaho State University)  
  [arXiv](https://arxiv.org/pdf/2410.02536)  
  **Keywords**: Inteligencia emergente, autómatas celulares elementales, complejidad, edge of chaos, LLMs, representaciones, razonamiento, predicción de jugadas de ajedrez  
  **Descripción**: Este estudio explora la relación entre la complejidad de sistemas basados en autómatas celulares elementales (ECA) y la emergencia de inteligencia en modelos de lenguaje grandes (*LLMs*). Se entrena una variante modificada del GPT-2 sobre datos generados por diversas reglas de ECA y se evalúa su desempeño en tareas de razonamiento y predicción de jugadas de ajedrez. Los resultados indican que la eficiencia de los modelos mejora al preentrenarse con datos de complejidad intermedia, sugiriendo un “punto óptimo” o "edge of chaos" para el aprendizaje efectivo.

* **Large Language Diffusion Models** (18 feb 2025 – Renmin University of China, Ant Group)  
  [arXiv](https://arxiv.org/pdf/2502.09992)  
  **Keywords**: Modelos de lenguaje grandes, difusión, generative modeling, in-context learning, razonamiento inverso, escalabilidad  
  **Descripción**: Este estudio introduce LLaDA, un modelo de difusión para grandes modelos de lenguaje entrenado desde cero bajo un paradigma de preentrenamiento y fine-tuning supervisado. A diferencia de los modelos autoregresivos tradicionales, LLaDA define la distribución del modelo mediante un proceso de enmascaramiento aleatorio y un predictor de máscaras basado en Transformers, lo que permite capturar dependencias bidireccionales y superar limitaciones inherentes a la generación token a token. Los resultados demuestran que LLaDA es competitivo en escalabilidad y rendimiento en tareas de comprensión, matemáticas, generación de código y diálogo, estableciendo a los modelos de difusión como una alternativa prometedora a los enfoques autoregresivos.

* **Frontier Models are Capable of In-context Scheming** (16 ene 2025 – Apollo Research)  
  [arXiv](https://arxiv.org/pdf/2412.04984) / [video](https://www.anthropic.com/news/tracing-thoughts-language-model) 
  **Keywords**: modelos frontera, razonamiento in-context, estrategias emergentes, planificación, inteligencia artificial  
  **Descripción**: Este estudio analiza la capacidad de los modelos de inteligencia artificial para generar y ejecutar esquemas complejos basados en el contexto proporcionado, destacando su potencial en tareas de razonamiento estratégico y planificación.

* **On the Biology of a Large Language Model** (27 mar 2025 – Anthropic)  
  [Transformer Circuits](https://transformer-circuits.pub/2025/attribution-graphs/biology.html)  
  **Keywords**: biología de modelos de lenguaje, circuitos de atribución, interpretabilidad, análisis de circuitos, Claude 3.5 Haiku  
  **Descripción**: Este artículo investiga los mecanismos internos utilizados por Claude 3.5 Haiku, el modelo de producción de Anthropic, a través de la metodología de trazado de circuitos. Se examinan diversos casos de estudio –desde razonamiento multi-paso y planificación en poesía hasta diagnósticos médicos y detección de entidades– para revelar cómo el modelo organiza y procesa información internamente, utilizando “grafos de atribución” que actúan como un “diagrama de cableado” de sus procesos computacionales.

* **Circuit Tracing: Revealing Computational Graphs in Language Models** (27 mar 2025 – Anthropic)  
  [Transformer Circuits](https://transformer-circuits.pub/2025/attribution-graphs/methods.html)  
  **Keywords**: trazado de circuitos, grafos de atribución, interpretabilidad, modelos transformadores, mecanismos de computación  
  **Descripción**: Este artículo describe un método para revelar los mecanismos subyacentes en el funcionamiento de modelos de lenguaje. Los autores construyen “grafos de atribución” que representan, de forma interpretable, los pasos computacionales que el modelo realiza al procesar una entrada. Se introduce la idea de un “modelo de reemplazo”, donde se sustituye parte del modelo original por componentes más interpretables, permitiendo analizar interacciones lineales entre características y validar circuitos a través de experimentos de perturbación. Además, se discuten herramientas de visualización y evaluación que facilitan la interpretación de estos grafos y, por tanto, una comprensión más profunda de las decisiones del modelo.

</details>  

<!--<details markdown="1">
<summary><strong>Recursos:</strong></summary>
</details>-->



## 02/04/2025 - Multimodalidad

**Image-to-LaTeX Converter for Mathematical Formulas and Text** (7 ago 2024 – Saarland University)  
[arXiv](https://arxiv.org/abs/2408.04015)  | [GitHub](https://github.com/d-gurgurov/im2latex?tab=readme-ov-file)  

<details markdown="1">

<summary><strong>Resumen:</strong></summary>


**Keywords**: Multimodalidad, Imagen, Texto, OCR, *transformers*, LoRA  

**Descripción**: En este proyecto se entrena un modelo encoder-decoder de visión para generar código LaTeX a partir de imágenes que contienen fórmulas matemáticas y texto. Se desarrollan dos versiones: una base, que utiliza un encoder basado en Swin Transformer y un decodificador basado en GPT-2 entrenado con imágenes generadas automáticamente, y otra afinada mediante Low-Rank Adaptation (LoRA) entrenada con fórmulas manuscritas. Se evalúa la calidad de la conversión mediante la métrica BLEU y se comparan los resultados con modelos similares, como Pix2Text, TexTeller y Sumen. El proyecto aporta modelos de código abierto y código desde cero para la construcción de estos sistemas con entrenamiento distribuido y optimización en GPU.

</details>

<!--<details markdown="1">
  <summary><strong>Referencias relevantes:</strong></summary>
</details>-->

<details markdown="1">
  <summary><strong>Otros *papers* (ideas para próximos grupos de lectura)/recursos:</strong></summary>

  ***Papers:***

  * **MinerU: An Open-Source Solution for Precise Document Content Extraction** (2024 – arXiv)  
  [arXiv](https://arxiv.org/abs/2409.18839)  
  **Keywords**: extracción de contenido, documentos, código abierto, visión por computador  
  **Descripción**: Este artículo presenta MinerU, una solución de código abierto para la extracción precisa de contenido en documentos. Los autores proponen un método innovador que integra técnicas de procesamiento de imagen y algoritmos de reconocimiento para identificar y extraer información relevante, validándolo mediante experimentos comparativos.

  * **Reasoning Models Don't Always Say What They Think** (3 abr 2025 – Anthropic)  
  [Anthropic](https://www.anthropic.com/research/reasoning-models-dont-say-think)  
  **Keywords**: Modelos de lenguaje, razonamiento, explicaciones no fieles  
  **Descripción**: Este estudio examina la fidelidad de las explicaciones generadas por modelos de lenguaje en procesos de razonamiento. Se encontró que, aunque los modelos utilizan pistas proporcionadas en las preguntas para formular sus respuestas, a menudo omiten mencionar estas pistas en sus explicaciones, lo que plantea preocupaciones sobre la transparencia y confiabilidad de sus procesos de razonamiento.

  * **PaperBench: Evaluating AI’s Abilities to Replicate AI Research** (2025 – OpenAI)  
  [OpenAI](https://cdn.openai.com/papers/22265bac-3191-44e5-b057-7aaacd8e90cd/paperbench.pdf)  
  **Keywords**: replicación, benchmark, inteligencia artificial, evaluación, rúbricas  
  **Descripción**: Este artículo presenta PaperBench, un benchmark diseñado para evaluar la capacidad de agentes de IA para replicar investigaciones en el ámbito de la inteligencia artificial. Los agentes deben replicar por completo los experimentos descritos en 20 artículos presentados en ICML 2024, partiendo de cero y sin utilizar el código original. La evaluación se fundamenta en rúbricas detalladas, co-diseñadas con los autores de los trabajos, que desglosan cada proceso de replicación en múltiples sub-tareas (desde la implementación del código hasta la ejecución y verificación de resultados). Además, se introduce un evaluador automático basado en LLM para calificar escalablemente cada intento de replicación.  
  **Replica de google**: 
  [AI co-scientist](https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/)  
  [Resultados](https://www.forbes.com/sites/lesliekatz/2025/02/19/google-unveils-ai-co-scientist-to-supercharge-research-breakthroughs/)  
  **Sarkana**:  
  [The AI Scientist Generates its First Peer-Reviewed Scientific Publication](https://sakana.ai/ai-scientist-first-publication/)



  * **Neuroscience-Inspired Artificial Intelligence** (19 jul 2017 – Deepmind)  
  [Neuron](https://doi.org/10.1016/j.neuron.2017.06.011)  
  **Keywords**: Inteligencia artificial, neurociencia, modelos inspirados en el cerebro  
  **Descripción**: Este artículo argumenta que una mejor comprensión de los cerebros biológicos puede desempeñar un papel vital en la construcción de máquinas inteligentes. Se examinan las interacciones históricas entre los campos de la inteligencia artificial y la neurociencia, destacando avances actuales en IA inspirados en el estudio de la computación neuronal en humanos y otros animales. Se concluye resaltando temas compartidos que pueden ser clave para avanzar en futuras investigaciones en ambos campos.

  * **LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models** (14 nov 2024 – NVIDIA)  
  [arXiv](https://arxiv.org/abs/2411.09595)  
  **Keywords**: Modelos de lenguaje grandes (*LLMs*), generación de mallas 3D, integración de modalidades, conocimiento espacial, tokenización de mallas  
  **Descripción**: Este estudio explora la ampliación de las capacidades de los *LLMs* entrenados en texto para generar mallas 3D. Se propone representar las coordenadas de los vértices y las definiciones de las caras como texto, lo que permite la integración directa sin necesidad de expandir el vocabulario. Se construye un conjunto de datos para *fine-tuning* supervisado que habilita la generación de mallas a partir de indicaciones textuales, la producción de salidas intercaladas (texto y mallas) y la comprensión de las mallas. Con este enfoque, LLaMA-Mesh alcanza una calidad comparable a la de modelos entrenados desde cero sin afectar el rendimiento en la generación textual.

  * **A unified acoustic-to-speech-to-language embedding space captures the neural basis of natural language processing in everyday conversations** (31 mar 2025 – Google, Princeton)  
  [Nature Human Behaviour](https://www.nature.com/articles/s41562-025-02105-9)  
  **Keywords**: procesamiento del lenguaje natural, embeddings acústico-habla-lingüística, electrocorticografía (ECoG), modelo multimodal, conversaciones reales  
  **Descripción**: Este estudio introduce un marco computacional unificado que integra representaciones acústicas, de habla y lingüísticas extraídas de un modelo multimodal (*Whisper*) para predecir la actividad neural durante conversaciones cotidianas. Mediante el uso de electrocorticografía en pacientes durante interacciones naturales, se mapea la alineación entre las distintas capas del modelo y las áreas cerebrales implicadas en la percepción y producción del lenguaje, demostrando una correlación robusta en la actividad neuronal.

  * **Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems** (31 mar 2025 – Google, Meta ...)  
  [arXiv](https://www.arxiv.org/abs/2504.01990) | [github_papers](https://github.com/FoundationAgents/awesome-foundation-agents?tab=readme-ov-file)
  **Keywords**: Modelos de lenguaje grandes (*LLMs*), agentes inteligentes, auto-mejora, evolución colaborativa, seguridad  
  **Descripción**: Este artículo ofrece una revisión exhaustiva sobre los fundamentos y desafíos en el desarrollo de agentes inteligentes basados en modelos de lenguaje grandes. Se explora una arquitectura modular inspirada en el cerebro humano que integra componentes para la percepción, memoria, modelado del mundo, procesamiento de recompensas y sistemas análogos a las emociones. Además, se analizan mecanismos de auto-mejora y evolución adaptativa, así como la colaboración en sistemas multiagente, subrayando la necesidad de construir sistemas seguros, éticos y robustos para su implementación en entornos reales.

  ***Recursos:***

  * 🔥***LLM Reasoning Papers*** (15 ene 2025 – philschmid)  
    Repositorio de artículos  
    [Hugging Face](https://huggingface.co/collections/philschmid/llm-reasoning-papers-66e6abbdf5579b829f214de8)  
    **Descripción**: Colección curada que reúne artículos para mejorar las capacidades de razonamiento de los modelos de lenguaje grandes.  

  * ***Awesome LLM*** (2025 – autor: Hannibal046)  
    Repositorio de artículos 
    [GitHub](https://github.com/Hannibal046/Awesome-LLM)  
    **Descripción**: Repositorio que recopila una amplia variedad de recursos, herramientas y proyectos relacionados con los modelos de lenguaje grandes (LLMs).

  * ***Mixture of Experts Explained*** (11 dic 2023 – Hugging Face)  
    Blog  
    [Hugging Face Blog](https://huggingface.co/blog/moe)  
    **Descripción**: Entrada del blog que explica en detalle el concepto de Mixture of Experts (MoE), sus fundamentos, ventajas, desafíos y aplicaciones en modelos de lenguaje y transformers, con énfasis en técnicas de entrenamiento y fine-tuning para modelos dispersos.

  * ***How Scaling Laws Drive Smarter, More Powerful AI*** (12 feb 2025 – NVIDIA)  
    Blog  
    [Blog de NVIDIA](https://blogs.nvidia.com/blog/ai-scaling-laws/#:~:text=Scaling%20laws%20describe%20how%20the,parameters%20or%20computational%20resources%20increases.)  
    **Descripción**: Entrada del blog que detalla cómo las leyes de escalabilidad en IA establecen la relación entre la cantidad de datos, parámetros y recursos computacionales con la mejora en el rendimiento de los modelos. Explica conceptos de preentrenamiento, postentrenamiento y escalado en tiempo de inferencia, poniendo especial énfasis en la importancia de aplicar computación acelerada para soportar modelos de razonamiento complejo.
  
  * ***Automating GPU Kernel Generation with DeepSeek R1 and Inference Time Scaling*** (fecha – NVIDIA Developer)  
    Blog  
    [Developer Blog de NVIDIA](https://developer.nvidia.com/blog/automating-gpu-kernel-generation-with-deepseek-r1-and-inference-time-scaling/)  
    **Descripción**: Entrada del blog que explica cómo DeepSeek R1 automatiza la generación de kernels para GPU, permitiendo optimizar el rendimiento en tiempo de inferencia. El artículo aborda técnicas avanzadas de deep learning para la generación eficiente de código en GPU y describe cómo el escalado en tiempo de inferencia puede mejorar la eficiencia y capacidad de respuesta de los modelos de inteligencia artificial en producción.

  * ***NVIDIA: Cursos RAG + Agentes*** (NVIDIA)  
    Curso  
    [Buscar Cursos](https://www.nvidia.com/en-us/training/find-training/) | [RAG 1](https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+S-FX-15+V1) | [RAG 2](https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+S-FX-16+V1)  
    **Descripción**: Agentes + RAG + Cursos varios
  
  * 🔥🔥🔥***Data-optimal scaling laws*** (2025 – Life Architect)  
    Blog  
    [Blog](https://lifearchitect.ai/chinchilla/)  
    **Descripción**: Resumen del escaladado de datos (ratio datos/parametros para maximizar un coste computacional dado)


</details>


<details markdown="1">

<summary><strong>Recursos:</strong></summary>



* 🔥***Awesome Multimodal LLMs*** (2024 – BradyFU)  
  Repositorio de artículos  
  [GitHub](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models)  
  **Descripción**: Repositorio que recopila y organiza recursos, herramientas y proyectos relacionados con modelos de lenguaje grandes multimodales, facilitando el acceso a información y ejemplos prácticos sobre esta temática.


* Vision Parser: 🔥🔥🔥 Acepta múltiples modelos. Basado en Ollama.  
  [git](https://github.com/iamarunbrahma/vision-parse)
  
* 🔥🔥🔥 AnyModel (2025) (image encoder) with Llama 3.2-1B. 🔥🔥🔥 AnyModal es un framework modular y extensible para integrar diversas modalidades de entrada.
  [git](https://github.com/ritabratamaiti/AnyModal), [HF](https://huggingface.co/AnyModal/LaTeX-OCR-Llama-3.2-1B),  [dataset 1](https://huggingface.co/datasets/unsloth/LaTeX_OCR), [dataset 2](https://huggingface.co/datasets/linxy/LaTeX_OCR)

* MinerU (2025): Converts PDFs into machine-readable formats
  [git](https://github.com/opendatalab/MinerU), [doc](https://mineru.readthedocs.io/en/latest/index.html), [api](https://mineru.readthedocs.io/en/latest/user_guide/usage/api.html)  
  AGPL


* **im2latex** (7 ago 2024 – GitHub)  
  [GitHub](https://github.com/d-gurgurov/im2latex?tab=readme-ov-file)  
  **Descripción**: Repositorio que contiene código y documentación para un convertidor de imágenes a LaTeX, facilitando la transformación de fórmulas matemáticas y texto a código LaTeX mediante técnicas de visión por ordenador.

* **TexTeller** (6 jun 2024 – GitHub)  
  [GitHub](https://github.com/OleehyO/TexTeller)  
  **Descripción**: Repositorio que ofrece un sistema de reconocimiento de fórmulas en imágenes, permitiendo convertir imágenes a código LaTeX con alta precisión y robustez, basado en modelos end-to-end y técnicas avanzadas de OCR.

* ⚠️**Pix2Text** (15 jul 2024 – GitHub) ⭐⭐⭐  
  [GitHub](https://github.com/breezedeus/Pix2Text)  
  **Descripción**: Repositorio que proporciona un modelo para convertir imágenes en texto. Basado en técnicas de OCR y aprendizaje profundo, destaca por su capacidad de generalización y precisión en la extracción de contenido visual.

</details>
