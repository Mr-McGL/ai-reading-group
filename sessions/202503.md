# Reading Group (Marzo)

## 03/03/2025 - Razonamiento III 

**Competitive Programming with Large Reasoning Models** (feb 2025 - OpenAI)  
[https://arxiv.org/abs/2502.06807](https://arxiv.org/abs/2502.06807)  

<details markdown="1">
<summary><strong>Resumen:</strong></summary>

*Key points:* 

  * Aprendizaje por refuerzo (*reinforcement learning*)  

Este estudio demuestra que el uso de aprendizaje por refuerzo (*reinforcement learning*) en modelos de lenguaje de gran tamaño mejora significativamente el rendimiento en tareas complejas de programación y razonamiento.

</details>

<details markdown="1">
  <summary><strong>Referencias relevantes: </strong></summary>
    
  * **Agentless: Demystifying LLM-based Software Engineering Agents** (1 jul 2024 – University of Illinois)  
  [arXiv](https://arxiv.org/abs/2407.01489) | [GitHub](https://github.com/OpenAutoCoder/Agentless)  
  **Keywords**: Agentización, modelos de lenguaje grandes (*LLMs*), automatización
  **Descripción**: Este trabajo presenta, un enfoque simplificado para resolver problemas de desarrollo de software sin recurrir a agentes autónomos complejos. A diferencia de métodos anteriores que utilizan agentes capaces de ejecutar comandos y planificar acciones, **Agentless** emplea un proceso de tres fases: localización del problema, reparación y validación del parche. El estudio destaca el potencial de técnicas más simples y rentables en el desarrollo autónomo de software.

  * **Kimi k1.5: Scaling Reinforcement Learning with LLMs** (22 ene 2025 – Kimi Team)  
  [arXiv](https://arxiv.org/abs/2501.12599) | [GitHub](https://github.com/MoonshotAI/Kimi-k1.5)  
  **Keywords**: Razonamiento, modelos de lenguaje grandes (*LLMs*), aprendizaje por refuerzo (*Reinforcement Learning*), multimodalidad  
  **Descripción**: Este trabajo presenta **Kimi k1.5**, un modelo multimodal de lenguaje de gran tamaño entrenado mediante aprendizaje por refuerzo. El modelo destaca por su capacidad para procesar contextos largos de hasta 128k tokens y por su rendimiento superior en tareas de razonamiento, alcanzando puntuaciones de 77.5 en AIME y 96.2 en MATH 500. Además, introduce técnicas para mejorar modelos de razonamiento de cadena corta (*short-CoT*), superando significativamente a modelos existentes como GPT-4o y Claude Sonnet 3.5. El repositorio de GitHub proporciona el informe completo y recursos adicionales.

  * **OpenAI o1 System Card** (5 dic 2024 – OpenAI)  
  [arXiv](https://arxiv.org/abs/2412.16720)  
  **Keywords**: Modelos de lenguaje grandes (*LLMs*), razonamiento, seguridad, alineación deliberativa  
  **Descripción**: Como citar los modelos de OpenAI.

  * **Toolformer: Language Models Can Teach Themselves to Use Tools** (9 feb 2023 – META/Pompeu Fabra)  
  [arXiv](https://arxiv.org/abs/2302.04761) | [GitHub](https://github.com/conceptofmind/toolformer)  
  **Keywords**: Modelos de lenguaje grandes (*LLMs*), herramientas externas, aprendizaje auto-supervisado  
  **Descripción**: Este trabajo introduce **Toolformer**, un modelo que se entrena para decidir qué APIs llamar, cuándo llamarlas, qué argumentos pasar y cómo incorporar mejor los resultados en la predicción de tokens futuros. 

  * **Chain-of-Thought Prompting Elicits Reasoning in Large Language Models** (28 ene 2022 – Google)  
  [arXiv](https://arxiv.org/abs/2201.11903)  
  **Keywords**: Modelos de lenguaje grandes (*LLMs*), razonamiento, *Chain-of-Thought Prompting*  
  **Descripción**: Este trabajo explora cómo la generación de una cadena de pensamiento—una serie de pasos de razonamiento intermedios—mejora significativamente la capacidad de los modelos de lenguaje grandes para realizar razonamientos complejos. 
  
</details>

<details markdown="1">
  <summary><strong>Otros papers (ideas para próximos grupos de lectura):</strong></summary>

  * **Order Doesn't Matter, But Reasoning Does: Training LLMs with Order-Centric Augmentation** (27 feb 2025 – Shanghai)  
  [arXiv](https://arxiv.org/abs/2502.19907)  
  **Keywords**: Modelos de lenguaje grandes (*LLMs*), razonamiento lógico, aumento de datos centrado en el orden  
  **Descripción**: Este estudio aborda la sensibilidad de los modelos de lenguaje grandes al orden de las premisas y los pasos de razonamiento. 

  * **Chain of Draft: Thinking Faster by Writing Less** (25 feb 2025 – Zoom Communications)  
  [arXiv](https://arxiv.org/abs/2502.18600)  
  **Keywords**: Razonamiento, *Chain of Thought* (cadena de pensamiento), eficiencia  
  **Descripción**: Este trabajo propone "Chain of Draft" (CoD), una estrategia de *prompting*, donde los modelos de lenguaje generan razonamientos intermedios mínimos pero informativos al resolver tareas. Al reducir la verbosidad y centrarse en ideas clave, CoD iguala "Chain of Thought" (CoT) utilizando solo el 7,6% de los tokens, lo que reduce significativamente el coste y la latencia en diversas tareas de razonamiento. 

  * **Don't Do RAG: When Cache-Augmented Generation is All You Need for Knowledge Tasks** (20 dic 2024 – Taiwan)  
  [arXiv](https://arxiv.org/abs/2412.15605)  
  **Keywords**: Modelos de lenguaje grandes (*LLMs*), generación aumentada por recuperación (*Retrieval-Augmented Generation* - RAG), generación aumentada por caché (*Cache-Augmented Generation* - CAG), eficiencia  
  **Descripción**: Este trabajo propone la **generación aumentada por caché** (*Cache-Augmented Generation* - CAG) como una alternativa a la generación aumentada por recuperación (*Retrieval-Augmented Generation* - RAG) en modelos de lenguaje grandes. CAG implica precargar todos los recursos relevantes en el contexto extendido del modelo antes de la inferencia, eliminando la necesidad de recuperación en tiempo real. 

  * **Prompt Cache: Modular Attention Reuse for Low-Latency Inference** (7 nov 2023 – Google, Yale)  
  [arXiv](https://arxiv.org/abs/2311.04934)  
  **Keywords**: Modelos de lenguaje grandes (*LLMs*), reutilización de estados de atención, inferencia de baja latencia  
  **Descripción**: Este trabajo presenta **Prompt Cache**, una técnica para acelerar la inferencia en modelos de lenguaje grandes mediante la reutilización de estados de atención en diferentes *prompts*. 

  * **Auditing Prompt Caching in Language Model APIs** (11 feb 2025 – Stanford)    
  [arXiv](https://arxiv.org/abs/2502.07776)  
  **Keywords**: Modelos de lenguaje grandes (*LLMs*), almacenamiento en caché de *prompts*, ataques de canal lateral, privacidad  
  **Descripción**: Este estudio investiga cómo el almacenamiento en caché de *prompts* en APIs de modelos de lenguaje grandes puede introducir variaciones en los tiempos de respuesta, lo que podría ser explotado en ataques de canal lateral. Mediante auditorías estadísticas, los autores detectaron que 8 de 17 proveedores de APIs, incluyendo OpenAI, comparten cachés globalmente entre usuarios, lo que podría permitir a un atacante inferir información sobre los *prompts* de otros usuarios basándose en tiempos de respuesta más rápidos. 
  
  * **Minions: Cost-efficient Collaboration Between On-device and Cloud Language Models** (21 feb 2025 – Stanford)  
  [arXiv](https://arxiv.org/abs/2502.15964)  
  **Keywords**: Modelos de lenguaje grandes (*LLMs*), colaboración local-remota, eficiencia de costos, razonamiento sobre datos extensos, seguridad  
  **Descripción**: Este estudio investiga cómo un modelo de lenguaje pequeño, operando en un dispositivo local con acceso a datos locales, puede colaborar con un modelo de lenguaje avanzado alojado en la nube para abordar tareas del mundo real que implican razonamiento financiero, médico y científico sobre documentos extensos. 

  * **From Local to Global: A Graph RAG Approach to Query-Focused Summarization** (24 abr 2024 – Microsoft)  
  [arXiv](https://arxiv.org/abs/2404.16130v1)    [arXiv](https://arxiv.org/abs/2404.16130v1)  
  **Keywords**: Modelos de lenguaje grandes (*LLMs*), generación aumentada por recuperación (*Retrieval-Augmented Generation* - RAG), resumen orientado a consultas (*Query-Focused Summarization* - QFS), grafos de conocimiento (*Knowledge Graphs*)    
  **Descripción**: Este trabajo introduce **Graph RAG**, una metodología que combina la generación aumentada por recuperación con grafos de conocimiento para abordar tareas de resumen orientado a consultas en grandes colecciones de texto.  

  * **LightRAG: Simple and Fast Retrieval-Augmented Generation** (8 oct 2024 – Beijing, Hong Kong)  nted Generation** (8 oct 2024 – Beijing, Hong Kong)  
  [arXiv](https://arxiv.org/abs/2410.05779v1) | [GitHub](https://github.com/HKUDS/LightRAG)  
  **Keywords**: Modelos de lenguaje grandes (*LLMs*), generación aumentada por recuperación (*Retrieval-Augmented Generation* - RAG), estructuras de grafos, eficiencia  
  **Descripción**: Este trabajo presenta **LightRAG**, un marco que incorpora estructuras de grafos en los procesos de indexación y recuperación de texto para mejorar los sistemas de generación aumentada por recuperación. El sistema emplea un mecanismo de recuperación de dos niveles que mejora la obtención de información tanto a nivel bajo como alto.   
  
  * **PathRAG: Pruning Graph-based Retrieval Augmented Generation with Relational Paths** (18 feb 2025 – Beijing, Hong Kong)  
  [arXiv](https://arxiv.org/abs/2502.14902) | [GitHub](https://github.com/BUPT-GAMMA/PathRAG)  
  **Keywords**: Modelos de lenguaje grandes (*LLMs*), generación aumentada por recuperación (*Retrieval-Augmented Generation* - RAG), grafos de conocimiento, eficiencia  
  **Descripción**: Este trabajo presenta **PathRAG**, una metodología que mejora la generación aumentada por recuperación basada en grafos al centrarse en rutas relacionales clave dentro del grafo de indexación. A diferencia de enfoques anteriores que pueden introducir redundancia al considerar información amplia de comunidades o vecinos inmediatos, **PathRAG** utiliza una poda basada en flujo para identificar y recuperar rutas esenciales entre nodos relacionados con la consulta. 

  * **Retrieval-Augmented Systems Can Be Dangerous Medical Communicators** (18 feb 2025 – MIT, Standford, Duke)  
  [arXiv](https://arxiv.org/abs/2502.14898v1)  
  **Keywords**: Modelos de lenguaje grandes (*LLMs*), generación aumentada por recuperación (*Retrieval-Augmented Generation* - RAG), comunicación médica, seguridad  
  **Descripción**: Este estudio analiza cómo los sistemas de generación aumentada por recuperación (RAG) pueden producir respuestas médicas que, aunque literalmente precisas y basadas en fuentes confiables, resultan pragmáticamente engañosas para los pacientes. 

  * **Agentic Reasoning: Reasoning LLMs with Tools for Deep Research** (7 feb 2025 – Oxford)  
  [arXiv](https://arxiv.org/abs/2502.04644) | [GitHub](https://github.com/theworldofagents/Agentic-Reasoning)  
  **Keywords**: *LLMs* (modelos de lenguaje grandes), razonamiento, agentes, herramientas externas, investigación profunda (*deep research*), *knowledge graph* (grafo de conocimiento), RAG
  **Descripción**: Este trabajo introduce **Agentic Reasoning**, un marco que mejora el razonamiento de los *LLMs* integrando *agents* que utilizan herramientas externas.  
 
</details>  

<details markdown="1">
<summary><strong>Recursos:</strong></summary>

  * **Test Time Scaling/Test Time Compute: Análisis de la literatura reciente** (feb 2025 - Discover IA - YouTube)  
    [https://www.youtube.com/watch?v=uqCoR_1jZPI](https://www.youtube.com/watch?v=uqCoR_1jZPI)  
    **Descripción**: Video que analiza distintos papers en el campo, desde modelos basados en PRM (*Process Review Models*) hasta los últimos modelos recurrentes que razonan en el espacio latente.

  * **Agentless** (25 feb 2025 – Zoom Communications)  
    [GitHub](https://github.com/OpenAutoCoder/Agentless)  
    **Descripción**: Repositorio del proyecto Agentless.

  * **Kimi k1.5** (22 ene 2025 – Kimi Team)  
    [GitHub](https://github.com/MoonshotAI/Kimi-k1.5)  
    **Descripción**: Repositorio del proyecto Kimi k1.5.

  * **The AI Reasoning Lie**  
    [https://www.youtube.com/watch?v=oE98PJefK4w](https://www.youtube.com/watch?v=oE98PJefK4w&ab_channel=DiscoverAI)  
    **Descripción**: Limitaciones de los modelos de razonamiento.
    
  * **LightRAG: Simple and Fast Retrieval-Augmented Generation** (8 oct 2024 – Beijing, Hong Kong)  
    [GitHub](https://github.com/HKUDS/LightRAG)  
    **Descripción**: Repositorio de **LightRAG**.

  * **PathRAG: Pruning Graph-based Retrieval Augmented Generation with Relational Paths** (18 feb 2025 – Beijing, Hong Kong)  
  [GitHub](https://github.com/BUPT-GAMMA/PathRAG)  
  **Descripción**: Repositorio de **PathRAG**.

  * **Agentic Reasoning: Reasoning LLMs with Tools for Deep Research** (7 feb 2025 – Oxford)  
  [GitHub](https://github.com/theworldofagents/Agentic-Reasoning)  
  **Descripción**: Repositorio de **Agentic Reasoning**.

  
</details>

## 18/03/2025 - Graph RAG

**From Local to Global: A Graph RAG Approach to Query-Focused Summarization** (abr 2024 - Microsoft Research)  
[https://arxiv.org/abs/2404.16130v1](https://arxiv.org/abs/2404.16130v1)

<details markdown="1">
<summary><strong>Resumen:</strong></summary>

*Puntos clave:* 

  * Uso de generación aumentada por recuperación (RAG) basada en grafos.
  * Construcción de un índice textual mediante un grafo de conocimiento derivado de un LLM.
  * Generación de resúmenes de comunidades mediante algoritmos de detección de comunidades.
  * Síntesis de respuestas parciales en una respuesta global que mejora la comprensión y diversidad.

Este estudio propone el método Graph RAG, que integra técnicas de recuperación-augmentada con la capacidad de los modelos de lenguaje para construir grafos de conocimiento. El enfoque segmenta el corpus en “comunidades” de información, genera resúmenes de cada una y, mediante un proceso de map-reduce, produce respuestas globales a preguntas orientadas al sentido global del conjunto de datos, ofreciendo mejoras significativas sobre los métodos convencionales.

*Conceptos clave:*

* QFS (Question-Focused Summarization) es una tarea de resumen que se centra en responder preguntas dirigidas a capturar la esencia global de un corpus de textos, en lugar de extraer información puntual de documentos individuales.
* LLM as Judge.
* Sensemaking: Sensemaking tasks require reasoning over “connections (which can be among people, places, and
events) in order to anticipate their trajectories and act effectively” (Klein et al., 2006).

</details>
<details markdown="1">
<summary><strong>Recursos:</strong></summary>

  * **Proyecto Graph RAG** (Microsoft Research)  
    [https://www.microsoft.com/en-us/research/project/graphrag/](https://www.microsoft.com/en-us/research/project/graphrag/)  
    **Descripción**: Sitio web oficial del proyecto Graph RAG, donde se ofrece información detallada, implementaciones y avances relacionados con este innovador enfoque de recuperación-augmentada mediante grafos.

</details>

<details markdown="1">
  <summary><strong>Otros papers (ideas para próximos grupos de lectura):</strong></summary>

* **Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena** (28 dec 2023 – UC Berkeley)  
  [OpenReview](https://openreview.net/forum?id=uccHPGDlao) | [GitHub](https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge)  
  **Keywords**: Modelos de lenguaje grandes (*LLMs*), preferencia humana, pruebas de evaluación, evaluación  
  **Descripción**: La evaluación de asistentes conversacionales basados en modelos de lenguaje grandes (LLMs) es desafiante debido a la falta de *benchmarks* adecuados para medir preferencias humanas. Se propone el enfoque *LLM-as-a-judge*, donde LLMs avanzados actúan como jueces en evaluaciones abiertas, analizando sesgos y limitaciones. La validación con **MT-bench** y **Chatbot Arena** muestra que modelos como GPT-4 alcanzan más del 80% de concordancia con evaluadores humanos, demostrando que *LLM-as-a-judge* es un método escalable y explicable que complementa los *benchmarks* tradicionales.

</details>
